  adding: debertav3large_lr11e-05_att_0007/ (stored 0%)
  adding: debertav3large_lr11e-05_att_0007/fold_3/ (stored 0%)
  adding: debertav3large_lr11e-05_att_0007/fold_3/added_tokens.json (stored 0%)
  adding: debertav3large_lr11e-05_att_0007/fold_3/3/ (stored 0%)
  adding: debertav3large_lr11e-05_att_0007/fold_3/3/checkpoint-2700/ (stored 0%)
  adding: debertav3large_lr11e-05_att_0007/fold_3/3/checkpoint-2700/rng_state.pth (deflated 28%)
  adding: debertav3large_lr11e-05_att_0007/fold_3/3/checkpoint-2700/added_tokens.json (stored 0%)
  adding: debertav3large_lr11e-05_att_0007/fold_3/3/checkpoint-2700/optimizer.pt (deflated 34%)
  adding: debertav3large_lr11e-05_att_0007/fold_3/3/checkpoint-2700/training_args.bin (deflated 49%)
  adding: debertav3large_lr11e-05_att_0007/fold_3/3/checkpoint-2700/pytorch_model.bin (deflated 15%)
  adding: debertav3large_lr11e-05_att_0007/fold_3/3/checkpoint-2700/scheduler.pt (deflated 49%)
  adding: debertav3large_lr11e-05_att_0007/fold_3/3/checkpoint-2700/spm.model (deflated 50%)
  adding: debertav3large_lr11e-05_att_0007/fold_3/3/checkpoint-2700/special_tokens_map.json (deflated 54%)
  adding: debertav3large_lr11e-05_att_0007/fold_3/3/checkpoint-2700/tokenizer_config.json (deflated 45%)
  adding: debertav3large_lr11e-05_att_0007/fold_3/3/checkpoint-2700/trainer_state.json (deflated 80%)
  adding: debertav3large_lr11e-05_att_0007/fold_3/3/checkpoint-2700/tokenizer.json (deflated 77%)
  adding: debertav3large_lr11e-05_att_0007/fold_3/3/checkpoint-2700/config.json (deflated 53%)
  adding: debertav3large_lr11e-05_att_0007/fold_3/pytorch_model.bin (deflated 15%)
  adding: debertav3large_lr11e-05_att_0007/fold_3/spm.model (deflated 50%)
  adding: debertav3large_lr11e-05_att_0007/fold_3/special_tokens_map.json (deflated 54%)
  adding: debertav3large_lr11e-05_att_0007/fold_3/tokenizer_config.json (deflated 45%)
  adding: debertav3large_lr11e-05_att_0007/fold_3/tokenizer.json (deflated 77%)
  adding: debertav3large_lr11e-05_att_0007/fold_3/config.json (deflated 53%)
  adding: debertav3large_lr11e-05_att_0007/fold_2/ (stored 0%)
  adding: debertav3large_lr11e-05_att_0007/fold_2/added_tokens.json (stored 0%)
  adding: debertav3large_lr11e-05_att_0007/fold_2/pytorch_model.bin (deflated 15%)
  adding: debertav3large_lr11e-05_att_0007/fold_2/spm.model (deflated 50%)
  adding: debertav3large_lr11e-05_att_0007/fold_2/special_tokens_map.json (deflated 54%)
  adding: debertav3large_lr11e-05_att_0007/fold_2/tokenizer_config.json (deflated 45%)
  adding: debertav3large_lr11e-05_att_0007/fold_2/2/ (stored 0%)
  adding: debertav3large_lr11e-05_att_0007/fold_2/2/checkpoint-5600/ (stored 0%)
  adding: debertav3large_lr11e-05_att_0007/fold_2/2/checkpoint-5600/rng_state.pth (deflated 28%)
  adding: debertav3large_lr11e-05_att_0007/fold_2/2/checkpoint-5600/added_tokens.json (stored 0%)
  adding: debertav3large_lr11e-05_att_0007/fold_2/2/checkpoint-5600/optimizer.pt (deflated 34%)
  adding: debertav3large_lr11e-05_att_0007/fold_2/2/checkpoint-5600/training_args.bin (deflated 49%)
  adding: debertav3large_lr11e-05_att_0007/fold_2/2/checkpoint-5600/pytorch_model.bin (deflated 15%)
  adding: debertav3large_lr11e-05_att_0007/fold_2/2/checkpoint-5600/scheduler.pt (deflated 49%)
  adding: debertav3large_lr11e-05_att_0007/fold_2/2/checkpoint-5600/spm.model (deflated 50%)
  adding: debertav3large_lr11e-05_att_0007/fold_2/2/checkpoint-5600/special_tokens_map.json (deflated 54%)
  adding: debertav3large_lr11e-05_att_0007/fold_2/2/checkpoint-5600/tokenizer_config.json (deflated 45%)
  adding: debertav3large_lr11e-05_att_0007/fold_2/2/checkpoint-5600/trainer_state.json (deflated 82%)
  adding: debertav3large_lr11e-05_att_0007/fold_2/2/checkpoint-5600/tokenizer.json (deflated 77%)
  adding: debertav3large_lr11e-05_att_0007/fold_2/2/checkpoint-5600/config.json (deflated 53%)
  adding: debertav3large_lr11e-05_att_0007/fold_2/tokenizer.json (deflated 77%)
  adding: debertav3large_lr11e-05_att_0007/fold_2/config.json (deflated 53%)
  adding: debertav3large_lr11e-05_att_0007/fold_1/ (stored 0%)
  adding: debertav3large_lr11e-05_att_0007/fold_1/added_tokens.json (stored 0%)
  adding: debertav3large_lr11e-05_att_0007/fold_1/pytorch_model.bin (deflated 16%)
  adding: debertav3large_lr11e-05_att_0007/fold_1/spm.model (deflated 50%)
  adding: debertav3large_lr11e-05_att_0007/fold_1/special_tokens_map.json (deflated 54%)
  adding: debertav3large_lr11e-05_att_0007/fold_1/tokenizer_config.json (deflated 45%)
  adding: debertav3large_lr11e-05_att_0007/fold_1/tokenizer.json (deflated 77%)
  adding: debertav3large_lr11e-05_att_0007/fold_1/1/ (stored 0%)
  adding: debertav3large_lr11e-05_att_0007/fold_1/1/checkpoint-500/ (stored 0%)
  adding: debertav3large_lr11e-05_att_0007/fold_1/1/checkpoint-500/rng_state.pth (deflated 28%)
  adding: debertav3large_lr11e-05_att_0007/fold_1/1/checkpoint-500/added_tokens.json (stored 0%)
  adding: debertav3large_lr11e-05_att_0007/fold_1/1/checkpoint-500/optimizer.pt (deflated 35%)
  adding: debertav3large_lr11e-05_att_0007/fold_1/1/checkpoint-500/training_args.bin (deflated 49%)
  adding: debertav3large_lr11e-05_att_0007/fold_1/1/checkpoint-500/pytorch_model.bin (deflated 16%)
  adding: debertav3large_lr11e-05_att_0007/fold_1/1/checkpoint-500/scheduler.pt (deflated 49%)
  adding: debertav3large_lr11e-05_att_0007/fold_1/1/checkpoint-500/spm.model (deflated 50%)
  adding: debertav3large_lr11e-05_att_0007/fold_1/1/checkpoint-500/special_tokens_map.json (deflated 54%)
  adding: debertav3large_lr11e-05_att_0007/fold_1/1/checkpoint-500/tokenizer_config.json (deflated 45%)
  adding: debertav3large_lr11e-05_att_0007/fold_1/1/checkpoint-500/trainer_state.json (deflated 68%)
  adding: debertav3large_lr11e-05_att_0007/fold_1/1/checkpoint-500/tokenizer.json (deflated 77%)
  adding: debertav3large_lr11e-05_att_0007/fold_1/1/checkpoint-500/config.json (deflated 53%)
  adding: debertav3large_lr11e-05_att_0007/fold_1/config.json (deflated 53%)
  adding: debertav3large_lr11e-05_att_0007/fold_0/ (stored 0%)
  adding: debertav3large_lr11e-05_att_0007/fold_0/added_tokens.json (stored 0%)
  adding: debertav3large_lr11e-05_att_0007/fold_0/0/ (stored 0%)
  adding: debertav3large_lr11e-05_att_0007/fold_0/0/checkpoint-3200/ (stored 0%)
  adding: debertav3large_lr11e-05_att_0007/fold_0/0/checkpoint-3200/rng_state.pth (deflated 28%)
  adding: debertav3large_lr11e-05_att_0007/fold_0/0/checkpoint-3200/added_tokens.json (stored 0%)
  adding: debertav3large_lr11e-05_att_0007/fold_0/0/checkpoint-3200/optimizer.pt (deflated 34%)
  adding: debertav3large_lr11e-05_att_0007/fold_0/0/checkpoint-3200/training_args.bin (deflated 49%)
  adding: debertav3large_lr11e-05_att_0007/fold_0/0/checkpoint-3200/pytorch_model.bin (deflated 15%)
  adding: debertav3large_lr11e-05_att_0007/fold_0/0/checkpoint-3200/scheduler.pt (deflated 49%)
  adding: debertav3large_lr11e-05_att_0007/fold_0/0/checkpoint-3200/spm.model (deflated 50%)
  adding: debertav3large_lr11e-05_att_0007/fold_0/0/checkpoint-3200/special_tokens_map.json (deflated 54%)
  adding: debertav3large_lr11e-05_att_0007/fold_0/0/checkpoint-3200/tokenizer_config.json (deflated 45%)
  adding: debertav3large_lr11e-05_att_0007/fold_0/0/checkpoint-3200/trainer_state.json (deflated 80%)
  adding: debertav3large_lr11e-05_att_0007/fold_0/0/checkpoint-3200/tokenizer.json (deflated 77%)
  adding: debertav3large_lr11e-05_att_0007/fold_0/0/checkpoint-3200/config.json (deflated 53%)
  adding: debertav3large_lr11e-05_att_0007/fold_0/pytorch_model.bin (deflated 15%)
  adding: debertav3large_lr11e-05_att_0007/fold_0/spm.model (deflated 50%)
  adding: debertav3large_lr11e-05_att_0007/fold_0/special_tokens_map.json (deflated 54%)
  adding: debertav3large_lr11e-05_att_0007/fold_0/tokenizer_config.json (deflated 45%)
  adding: debertav3large_lr11e-05_att_0007/fold_0/tokenizer.json (deflated 77%)
  adding: debertav3large_lr11e-05_att_0007/fold_0/config.json (deflated 53%)
Starting upload for file debertav3large_lr11e-05_att_0007.zip
Upload successful: debertav3large_lr11e-05_att_0007.zip (19GB)
Your private Dataset is being created. Please check progress at https://www.kaggle.com/datasets/phnghiapro/CL-debertav3large-lr11e-05-att-0007
  adding: debertav3large_lr12e-05_att_0007/ (stored 0%)
  adding: debertav3large_lr12e-05_att_0007/fold_3/ (stored 0%)
  adding: debertav3large_lr12e-05_att_0007/fold_3/added_tokens.json (stored 0%)
  adding: debertav3large_lr12e-05_att_0007/fold_3/3/ (stored 0%)
  adding: debertav3large_lr12e-05_att_0007/fold_3/3/checkpoint-4800/ (stored 0%)
  adding: debertav3large_lr12e-05_att_0007/fold_3/3/checkpoint-4800/rng_state.pth (deflated 28%)
  adding: debertav3large_lr12e-05_att_0007/fold_3/3/checkpoint-4800/added_tokens.json (stored 0%)
  adding: debertav3large_lr12e-05_att_0007/fold_3/3/checkpoint-4800/optimizer.pt (deflated 34%)
  adding: debertav3large_lr12e-05_att_0007/fold_3/3/checkpoint-4800/training_args.bin (deflated 49%)
  adding: debertav3large_lr12e-05_att_0007/fold_3/3/checkpoint-4800/pytorch_model.bin (deflated 15%)
  adding: debertav3large_lr12e-05_att_0007/fold_3/3/checkpoint-4800/scheduler.pt (deflated 49%)
  adding: debertav3large_lr12e-05_att_0007/fold_3/3/checkpoint-4800/spm.model (deflated 50%)
  adding: debertav3large_lr12e-05_att_0007/fold_3/3/checkpoint-4800/special_tokens_map.json (deflated 54%)
  adding: debertav3large_lr12e-05_att_0007/fold_3/3/checkpoint-4800/tokenizer_config.json (deflated 45%)
  adding: debertav3large_lr12e-05_att_0007/fold_3/3/checkpoint-4800/trainer_state.json (deflated 81%)
  adding: debertav3large_lr12e-05_att_0007/fold_3/3/checkpoint-4800/tokenizer.json (deflated 77%)
  adding: debertav3large_lr12e-05_att_0007/fold_3/3/checkpoint-4800/config.json (deflated 53%)
  adding: debertav3large_lr12e-05_att_0007/fold_3/pytorch_model.bin (deflated 15%)
  adding: debertav3large_lr12e-05_att_0007/fold_3/spm.model (deflated 50%)
  adding: debertav3large_lr12e-05_att_0007/fold_3/special_tokens_map.json (deflated 54%)
  adding: debertav3large_lr12e-05_att_0007/fold_3/tokenizer_config.json (deflated 45%)
  adding: debertav3large_lr12e-05_att_0007/fold_3/tokenizer.json (deflated 77%)
  adding: debertav3large_lr12e-05_att_0007/fold_3/config.json (deflated 53%)
  adding: debertav3large_lr12e-05_att_0007/fold_2/ (stored 0%)
  adding: debertav3large_lr12e-05_att_0007/fold_2/added_tokens.json (stored 0%)
  adding: debertav3large_lr12e-05_att_0007/fold_2/pytorch_model.bin (deflated 15%)
  adding: debertav3large_lr12e-05_att_0007/fold_2/spm.model (deflated 50%)
  adding: debertav3large_lr12e-05_att_0007/fold_2/special_tokens_map.json (deflated 54%)
  adding: debertav3large_lr12e-05_att_0007/fold_2/tokenizer_config.json (deflated 45%)
  adding: debertav3large_lr12e-05_att_0007/fold_2/2/ (stored 0%)
  adding: debertav3large_lr12e-05_att_0007/fold_2/2/checkpoint-2000/ (stored 0%)
  adding: debertav3large_lr12e-05_att_0007/fold_2/2/checkpoint-2000/rng_state.pth (deflated 28%)
  adding: debertav3large_lr12e-05_att_0007/fold_2/2/checkpoint-2000/added_tokens.json (stored 0%)
  adding: debertav3large_lr12e-05_att_0007/fold_2/2/checkpoint-2000/optimizer.pt (deflated 34%)
  adding: debertav3large_lr12e-05_att_0007/fold_2/2/checkpoint-2000/training_args.bin (deflated 49%)
  adding: debertav3large_lr12e-05_att_0007/fold_2/2/checkpoint-2000/pytorch_model.bin (deflated 15%)
  adding: debertav3large_lr12e-05_att_0007/fold_2/2/checkpoint-2000/scheduler.pt (deflated 49%)
  adding: debertav3large_lr12e-05_att_0007/fold_2/2/checkpoint-2000/spm.model (deflated 50%)
  adding: debertav3large_lr12e-05_att_0007/fold_2/2/checkpoint-2000/special_tokens_map.json (deflated 54%)
  adding: debertav3large_lr12e-05_att_0007/fold_2/2/checkpoint-2000/tokenizer_config.json (deflated 45%)
  adding: debertav3large_lr12e-05_att_0007/fold_2/2/checkpoint-2000/trainer_state.json (deflated 78%)
  adding: debertav3large_lr12e-05_att_0007/fold_2/2/checkpoint-2000/tokenizer.json (deflated 77%)
  adding: debertav3large_lr12e-05_att_0007/fold_2/2/checkpoint-2000/config.json (deflated 53%)
  adding: debertav3large_lr12e-05_att_0007/fold_2/tokenizer.json (deflated 77%)
  adding: debertav3large_lr12e-05_att_0007/fold_2/config.json (deflated 53%)
  adding: debertav3large_lr12e-05_att_0007/fold_1/ (stored 0%)
  adding: debertav3large_lr12e-05_att_0007/fold_1/added_tokens.json (stored 0%)
  adding: debertav3large_lr12e-05_att_0007/fold_1/pytorch_model.bin (deflated 16%)
  adding: debertav3large_lr12e-05_att_0007/fold_1/spm.model (deflated 50%)
  adding: debertav3large_lr12e-05_att_0007/fold_1/special_tokens_map.json (deflated 54%)
  adding: debertav3large_lr12e-05_att_0007/fold_1/tokenizer_config.json (deflated 45%)
  adding: debertav3large_lr12e-05_att_0007/fold_1/tokenizer.json (deflated 77%)
  adding: debertav3large_lr12e-05_att_0007/fold_1/1/ (stored 0%)
  adding: debertav3large_lr12e-05_att_0007/fold_1/1/checkpoint-2100/ (stored 0%)
  adding: debertav3large_lr12e-05_att_0007/fold_1/1/checkpoint-2100/rng_state.pth (deflated 28%)
  adding: debertav3large_lr12e-05_att_0007/fold_1/1/checkpoint-2100/added_tokens.json (stored 0%)
  adding: debertav3large_lr12e-05_att_0007/fold_1/1/checkpoint-2100/optimizer.pt (deflated 34%)
  adding: debertav3large_lr12e-05_att_0007/fold_1/1/checkpoint-2100/training_args.bin (deflated 49%)
  adding: debertav3large_lr12e-05_att_0007/fold_1/1/checkpoint-2100/pytorch_model.bin (deflated 16%)
  adding: debertav3large_lr12e-05_att_0007/fold_1/1/checkpoint-2100/scheduler.pt (deflated 49%)
  adding: debertav3large_lr12e-05_att_0007/fold_1/1/checkpoint-2100/spm.model (deflated 50%)
  adding: debertav3large_lr12e-05_att_0007/fold_1/1/checkpoint-2100/special_tokens_map.json (deflated 54%)
  adding: debertav3large_lr12e-05_att_0007/fold_1/1/checkpoint-2100/tokenizer_config.json (deflated 45%)
  adding: debertav3large_lr12e-05_att_0007/fold_1/1/checkpoint-2100/trainer_state.json (deflated 78%)
  adding: debertav3large_lr12e-05_att_0007/fold_1/1/checkpoint-2100/tokenizer.json (deflated 77%)
  adding: debertav3large_lr12e-05_att_0007/fold_1/1/checkpoint-2100/config.json (deflated 53%)
  adding: debertav3large_lr12e-05_att_0007/fold_1/config.json (deflated 53%)
  adding: debertav3large_lr12e-05_att_0007/fold_0/ (stored 0%)
  adding: debertav3large_lr12e-05_att_0007/fold_0/added_tokens.json (stored 0%)
  adding: debertav3large_lr12e-05_att_0007/fold_0/0/ (stored 0%)
  adding: debertav3large_lr12e-05_att_0007/fold_0/0/checkpoint-3200/ (stored 0%)
  adding: debertav3large_lr12e-05_att_0007/fold_0/0/checkpoint-3200/rng_state.pth (deflated 28%)
  adding: debertav3large_lr12e-05_att_0007/fold_0/0/checkpoint-3200/added_tokens.json (stored 0%)
  adding: debertav3large_lr12e-05_att_0007/fold_0/0/checkpoint-3200/optimizer.pt (deflated 34%)
  adding: debertav3large_lr12e-05_att_0007/fold_0/0/checkpoint-3200/training_args.bin (deflated 49%)
  adding: debertav3large_lr12e-05_att_0007/fold_0/0/checkpoint-3200/pytorch_model.bin (deflated 15%)
  adding: debertav3large_lr12e-05_att_0007/fold_0/0/checkpoint-3200/scheduler.pt (deflated 49%)
  adding: debertav3large_lr12e-05_att_0007/fold_0/0/checkpoint-3200/spm.model (deflated 50%)
  adding: debertav3large_lr12e-05_att_0007/fold_0/0/checkpoint-3200/special_tokens_map.json (deflated 54%)
  adding: debertav3large_lr12e-05_att_0007/fold_0/0/checkpoint-3200/tokenizer_config.json (deflated 45%)
  adding: debertav3large_lr12e-05_att_0007/fold_0/0/checkpoint-3200/trainer_state.json (deflated 80%)
  adding: debertav3large_lr12e-05_att_0007/fold_0/0/checkpoint-3200/tokenizer.json (deflated 77%)
  adding: debertav3large_lr12e-05_att_0007/fold_0/0/checkpoint-3200/config.json (deflated 53%)
  adding: debertav3large_lr12e-05_att_0007/fold_0/pytorch_model.bin (deflated 15%)
  adding: debertav3large_lr12e-05_att_0007/fold_0/spm.model (deflated 50%)
  adding: debertav3large_lr12e-05_att_0007/fold_0/special_tokens_map.json (deflated 54%)
  adding: debertav3large_lr12e-05_att_0007/fold_0/tokenizer_config.json (deflated 45%)
  adding: debertav3large_lr12e-05_att_0007/fold_0/tokenizer.json (deflated 77%)
  adding: debertav3large_lr12e-05_att_0007/fold_0/config.json (deflated 53%)
Starting upload for file debertav3large_lr12e-05_att_0007.zip
